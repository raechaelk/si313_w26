{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca7JhRUQnogm"
      },
      "source": [
        "# Correlation Assignment\n",
        "\n",
        "If you are using Google Colab to finish your assignment, make a copy to your own drive and edit.\n",
        "If you are running on your own local machine, you can install the `colab` extension in your own VSCode, and running with the colab kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQgaUSeoG85s"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqMv-CHHBjw"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "To get p-values, you have to use a library specifically built for statistical testing, like _SciPy_.\n",
        "\n",
        "`scipy` is the gold standard for scientific computing, but it is designed to calculate the correlation and p-value for one pair of variables at a time. It doesn't have a single \"matrix\" function like `df.corr()`.\n",
        "\n",
        "To create the correlation matrix and get p-values using `scipy`, you need to iterate through your column combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aNHF2_NwHEBs"
      },
      "outputs": [],
      "source": [
        "def get_scipy_corrs(df, variables):\n",
        "    \"\"\"\n",
        "    This is a helper function that returns a correlation matrix with p-values from scipy.\n",
        "\n",
        "    Args:\n",
        "      df (pandas.DataFrame): The input DataFrame.\n",
        "      variables (list): A list of column names to calculate correlations for.\n",
        "\n",
        "    Returns:\n",
        "      tuple: A tuple containing two pandas DataFrames:\n",
        "        - r_df (pandas.DataFrame): Correlation matrix with correlation coefficients.\n",
        "        - p_df (pandas.DataFrame): Correlation matrix with p-values.\n",
        "    \"\"\"\n",
        "    n = len(variables)\n",
        "    # Initialize with NaNs to handle cases where calculation fails\n",
        "    p_matrix = np.full((n, n), np.nan)\n",
        "    r_matrix = np.full((n, n), np.nan)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            # 1. Select the two columns and drop rows where either is NaN\n",
        "            subset = df[[variables[i], variables[j]]].dropna()\n",
        "\n",
        "            # 2. Ensure data is numeric and flattened to 1D arrays\n",
        "            x = subset[variables[i]].astype(float).values\n",
        "            y = subset[variables[j]].astype(float).values\n",
        "\n",
        "            # 3. Calculate (requires at least 2 points for a correlation)\n",
        "            if len(x) > 1:\n",
        "                try:\n",
        "                    res = stats.pearsonr(x, y)\n",
        "                    r_matrix[i, j] = res.statistic\n",
        "                    p_matrix[i, j] = res.pvalue\n",
        "                except:\n",
        "                    continue # Skip pairs that cause math errors (e.g. zero variance)\n",
        "\n",
        "    # Return as clean DataFrames\n",
        "    r_df = pd.DataFrame(r_matrix, index=variables, columns=variables)\n",
        "    p_df = pd.DataFrame(p_matrix, index=variables, columns=variables)\n",
        "    return r_df, p_df\n",
        "\n",
        "\n",
        "def format_sig_stars(p):\n",
        "    if p < 0.001: return '***'\n",
        "    if p < 0.01: return '**'\n",
        "    if p < 0.05: return '*'\n",
        "    return ''\n",
        "\n",
        "def combine_r_and_p(r_df, p_df):\n",
        "    \"\"\"\n",
        "    This is a helper function that combines the correlation and p-values.\n",
        "    \"\"\"\n",
        "    combined = r_df.copy().astype(str)\n",
        "\n",
        "    for i in range(len(r_df.index)):\n",
        "        for j in range(len(r_df.columns)):\n",
        "            r_val = r_df.iloc[i, j]\n",
        "            p_val = p_df.iloc[i, j]\n",
        "\n",
        "            if pd.isna(r_val) or pd.isna(p_val):\n",
        "                combined.iloc[i, j] = \"\"\n",
        "                continue\n",
        "\n",
        "            stars = format_sig_stars(p_val)\n",
        "            # Format: 0.123*** (p=0.002)\n",
        "            combined.iloc[i, j] = f\"{r_val:.3f}{stars}\\n({p_val:.3f})\"\n",
        "\n",
        "    return combined\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dke_BaIHGB8"
      },
      "source": [
        "Creating a table that follows APA conventions is a little tricky. We've written a function to help you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g1ZF29C8HIiK"
      },
      "outputs": [],
      "source": [
        "def export_apa_correlation(r_df, p_df):\n",
        "    # Create a mask for the upper triangle\n",
        "    mask = np.triu(np.ones_like(r_df, dtype=bool))\n",
        "\n",
        "    # Initialize the formatted DataFrame\n",
        "    apa_df = r_df.copy().astype(str)\n",
        "\n",
        "    for i in range(len(r_df.index)):\n",
        "        for j in range(len(r_df.columns)):\n",
        "            # Hide the upper triangle and diagonal\n",
        "            if i <= j:\n",
        "                apa_df.iloc[i, j] = \"\"\n",
        "                continue\n",
        "\n",
        "            r_val = r_df.iloc[i, j]\n",
        "            p_val = p_df.iloc[i, j]\n",
        "\n",
        "            # Add stars\n",
        "            stars = \"\"\n",
        "            if p_val < .001: stars = \"***\"\n",
        "            elif p_val < .01: stars = \"**\"\n",
        "            elif p_val < .05: stars = \"*\"\n",
        "\n",
        "            # Format to 2 or 3 decimal places (APA usually uses 2 or 3)\n",
        "            # This version keeps 3 for precision\n",
        "            formatted_r = f\"{r_val:.2f}\".replace(\"0.\", \".\") # Remove leading zero for APA style\n",
        "            apa_df.iloc[i, j] = f\"{formatted_r}{stars}\"\n",
        "\n",
        "    # Rename columns to 1, 2, 3... to follow APA table headers\n",
        "    apa_df.columns = [f\"{i+1}.\" for i in range(len(apa_df.columns))]\n",
        "    # Add the variable names as the first column\n",
        "    apa_df.insert(0, \"Variable\", r_df.index)\n",
        "    # Add a column for the index numbers\n",
        "    apa_df.insert(0, \"№\", range(1, len(apa_df) + 1))\n",
        "\n",
        "    return apa_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ5reXsbHLze"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "You'll need to download the data from the link in the assignment on Canvas. The filename you're looking for is `Dawtry Sutton and Sibley 2015 Study 1a.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qFNZNUuHJvP",
        "outputId": "d10b9114-c3e3-47ad-c0df-4719a6575342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (305, 37)\n",
            "\n",
            "Column names:\n",
            "['PS', 'PD_15', 'PD_30', 'PD_45', 'PD_60', 'PD_75', 'PD_90', 'PD_105', 'PD_120', 'PD_135', 'PD_150', 'PD_150plus', 'fairness', 'satisfaction', 'SC_15', 'SC_30', 'SC_45', 'SC_60', 'SC_75', 'SC_90', 'SC_105', 'SC_120', 'SC_135', 'SC_150', 'SC_150plus', 'redist1', 'redist2', 'redist3', 'redist4', 'Household_Income', 'Political_Preference', 'age', 'gender', 'Population_Inequality_Gini_Index', 'Population_Mean_Income', 'Social_Circle_Inequality_Gini_Index', 'Social_Circle_Mean_Income']\n",
            "\n",
            "First few rows:\n",
            "    PS  PD_15  PD_30  PD_45  PD_60  PD_75  PD_90  PD_105  PD_120  PD_135  ...  \\\n",
            "0  233     27     48     21      0      0      0       0       0       0  ...   \n",
            "1  157     39      0      0      0      0      0       0       0       0  ...   \n",
            "2  275      0      0     50      0      0     50       0       0       0  ...   \n",
            "3  111      9     14     17     17     17      8       7       5       2  ...   \n",
            "4   52     68     32      0      0      0      0       0       0       0  ...   \n",
            "\n",
            "   redist3  redist4  Household_Income  Political_Preference  age  gender  \\\n",
            "0        6        1                                       5   40       2   \n",
            "1        3        4                20                     5   59       2   \n",
            "2        5        5               100                     5   41       2   \n",
            "3        3        4               150                     8   59       2   \n",
            "4        4        5               500                     5   35       1   \n",
            "\n",
            "   Population_Inequality_Gini_Index  Population_Mean_Income  \\\n",
            "0                         38.782938                   29715   \n",
            "1                         37.214511                  123630   \n",
            "2                         20.750000                   60000   \n",
            "3                         35.379580                   59355   \n",
            "4                         16.875000                   15360   \n",
            "\n",
            "   Social_Circle_Inequality_Gini_Index  Social_Circle_Mean_Income  \n",
            "0                            28.056738                      21150  \n",
            "1                            24.323388                      65355  \n",
            "2                            14.442577                     107100  \n",
            "3                            26.925900                      86640  \n",
            "4                            21.401055                      56850  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the Dawtry et al. (2015) Study 1a data\n",
        "file_id = '0Bz-rhZ21ShvOMGxnYUJfYmR5d2M'\n",
        "resource_key = '0-jo7UtjyXsahMUKXVOQvb9g'\n",
        "\n",
        "# Construct a direct download link\n",
        "direct_link = f'https://drive.google.com/uc?export=download&id={file_id}&resourcekey={resource_key}'\n",
        "df = pd.read_csv(direct_link)\n",
        "\n",
        "# IF YOU ARE RUNNING ON YOUR OWN LAPTOP, UNCOMMENT AND ADD THE FILEPATH\n",
        "# df = pd.read_csv('')  # Add the correct path to the CSV file here\n",
        "\n",
        "# Explore the dataframe\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\\n{df.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9J30zG7AuY3"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "This section TO-DO list:\n",
        "  1. Understand the data with descriptive analysis\n",
        "  2. Compute two new variables\n",
        "\n",
        "Compute the two variables:  \n",
        "1. You should first create a score that captures participants’ perceptions that the current system is fair and satisfactory. To do this, COMPUTE the mean for the items fairness and satisfaction, naming this new variable `fairness_and_satisfaction`.    \n",
        "2. Next, you should create a score that captures participants’ support for redistribution. The researchers asked participants four questions in total, two asked about their support for redistribution, and two asked about their opposition to redistribution.\n",
        "3. To create a single score that reflect participants overall view toward redistribution, we first need to recode the two items that assess opposition to redistribution. Reverse score redist2 and redist4, so that 6 = 1, 5 = 2, 4 = 3, 3 = 4, 2 = 5, 1 = 6. Name the recoded variables `redist2_recode` and `redist4_recode`.\n",
        "4. Now, COMPUTE the mean for the items `redist1`, `redist2_recode`, `redist3`, `redist4_recode`, naming this new variable `support_for_redistribution`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LCf0Te5AAuFb"
      },
      "outputs": [],
      "source": [
        "# These are the relevant variables we'll use\n",
        "relevant_vars = ['fairness', 'satisfaction',\n",
        "                  'redist1', 'redist2', 'redist3', 'redist4',\n",
        "                  'Household_Income', 'Social_Circle_Mean_Income',\n",
        "                  'Population_Mean_Income', 'Social_Circle_Inequality_Gini_Index',\n",
        "                  'Population_Inequality_Gini_Index', 'Political_Preference']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7IDwSwQ_6sd"
      },
      "outputs": [],
      "source": [
        "# Data description, you can use .info() or .describe()\n",
        "## TODO: Conduct descriptive analysis, notice any missingness and weird stats\n",
        "## Remember to check the variables relevant to our study\n",
        "\n",
        "print(...) # .info() to check the missingness\n",
        "\n",
        "print(...) # .describe() to easily check the descriptive stats of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "894jTlT2Chzt"
      },
      "outputs": [],
      "source": [
        "# Creating two new variables\n",
        "## First step: compute the mean of fairness and satisfaction\n",
        "df['...'] = ...\n",
        "\n",
        "## Remember to double check if the new variable works\n",
        "print(f\"New variable created: {df['fairness_and_satisfaction'].describe()}\")\n",
        "print(f\"\\nMissing values: {df['fairness_and_satisfaction'].isna().sum()}\")\n",
        "print(df[['fairness', 'satisfaction', 'fairness_and_satisfaction']].head(10)) # use this code to check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT3TVHzKFVAa"
      },
      "outputs": [],
      "source": [
        "## Second step: reverse the redist2 and redist 4, you can use the formula: reversed = 7 - original\n",
        "\n",
        "df['...'] = ...\n",
        "df['...'] = ...\n",
        "\n",
        "# Verify a few cases like what we did for fairness and satisfaction\n",
        "print(df[...])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQSob-28Fsjl"
      },
      "outputs": [],
      "source": [
        "## Third step: compute the mean of all redistribution items\n",
        "df['...'] = ...\n",
        "\n",
        "# Verify again\n",
        "print(df[...])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oyxuHmmF5ZW"
      },
      "source": [
        "After we have done many cleaning for our dataset, it is important to check the descriptives again **before** doing any analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgc9G8U5F0zu"
      },
      "outputs": [],
      "source": [
        "# List of relevant variables we are going to use\n",
        "key_vars = ['Household_Income', 'Social_Circle_Mean_Income',\n",
        "                  'Population_Mean_Income', 'Social_Circle_Inequality_Gini_Index',\n",
        "                  'Population_Inequality_Gini_Index', 'fairness_and_satisfaction',\n",
        "            'support_for_redistribution', 'Political_Preference']\n",
        "\n",
        "# Check their descriptive analysis\n",
        "descriptives = ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqsrmO7rnc3N"
      },
      "outputs": [],
      "source": [
        "# Or we can present it in a formatted way:\n",
        "# Calculate descriptive statistics\n",
        "descriptives = df[key_vars].describe().loc[['mean', 'std', 'count']].T\n",
        "descriptives.columns = ['M', 'SD', 'N']\n",
        "descriptives = descriptives.round(2)\n",
        "\n",
        "print(\"Descriptive Statistics for Key Variables\")\n",
        "print(\"=\"*50)\n",
        "print(descriptives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7PU9slsG2uz"
      },
      "source": [
        "Notice anything weird? If not, we can proceed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hUnEbQrG767"
      },
      "source": [
        "## Correlation Analysis\n",
        "\n",
        "We are going through a typical workflow of conducting correlation analysis in Python\n",
        "- Check the data type `dtype` of variables: ensure all variables in correlation analysis are numeric, you can use `pd.to_numeric()` to transform non-numeric variables to numeric\n",
        "- Create a Pearson correlation matrix using `df.corr(method='pearson')` and try to visualize it\n",
        "- Use the helper function `get_scipy_corrs()` to get a correlation matrix with p-values\n",
        "- Finally, present our results in APA format using `export_apa_correlation()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ehM80Wk2NN"
      },
      "source": [
        "Now we first start from checking data types. You can use `.dtypes` in Pandas to check the data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEgr9P1zG7Gw"
      },
      "outputs": [],
      "source": [
        "# Checking data types\n",
        "print(df[...]...) # Fill in the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ZglqqLlEuS"
      },
      "source": [
        "Do you notice any variables that are not numeric? Try to transform them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wovAQTdFGxTP"
      },
      "outputs": [],
      "source": [
        "# Transform the non-numeric variables using pd.numeric()\n",
        "df[...] = df[...]..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ngQJONllRlq"
      },
      "source": [
        "Then, create a correlation matrix and a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAJfREy5lPyp"
      },
      "outputs": [],
      "source": [
        "# Calculate corrleation matrix\n",
        "# TO-DO: write the code here\n",
        "correlation_matrix = ...\n",
        "\n",
        "\n",
        "# Present it in a formatted way\n",
        "print(\"Correlation matrix\")\n",
        "print(\"=\"*50)\n",
        "print(correlation_matrix.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretation**: Explain the correlation matrix briefly. Tell us about what you found from the matrix in 2-3 sentences.\n",
        "(Respond here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYtwpVoQlh7q"
      },
      "source": [
        "To get p-values, you have to use a library specifically built for statistical testing, like _SciPy_.\n",
        "\n",
        "`scipy` is the gold standard for scientific computing, but it is designed to calculate the correlation and p-value for one pair of variables at a time. It doesn't have a single \"matrix\" function like `df.corr()`.\n",
        "\n",
        "To create the correlation matrix and get p-values using `scipy`, you need to iterate through your column combinations. Here we are using the helper function `get_scipy_corrs(df, variables)`. **In your own project, you need write your own helper functions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WoUPn-hlqzM"
      },
      "outputs": [],
      "source": [
        "# Get correlation matrix with p-values\n",
        "...\n",
        "\n",
        "# Generate the report with p-values and significance stars\n",
        "report_df = combine_r_and_p(...)\n",
        "print(report_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo8-0iG2mp1C"
      },
      "source": [
        "Prepare a correlation matrix that includes all of the relevant study variables. Make sure to follow APA-style guidelines.\n",
        "\n",
        "Tips: You can use `export_apa_correlation()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6--rP49jnAf-"
      },
      "outputs": [],
      "source": [
        "apa_table = ...\n",
        "apa_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-yozxRFnHB8"
      },
      "source": [
        "**BONUS**: draw a heatmap of the correlation matrix. Sometimes tables are overwhelming. We can use `seaborn` to draw a heatmap visualization and color the cells by the correlation strength.\n",
        "\n",
        "Tips: You can make a good use of the `heatmap()` in seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8x08tk3nRf-"
      },
      "outputs": [],
      "source": [
        "# Draw the heatmap here:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
